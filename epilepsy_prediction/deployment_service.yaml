apiVersion: apps/v1
kind: Deployment
metadata:
  name: epilepsy-prediction-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: eeg-app
      component: epilepsy-prediction
  template:
    metadata:
      labels:
        app: eeg-app
        component: epilepsy-prediction
    spec:
      containers:
      - name: epilepsy-prediction
        image: fberton98/epilepsy_prediction:latest
        ports:
        - containerPort: 5000
        resources:
          limits: # max quantity of resources that container can use, otherwise --> throttled
            cpu: 400m
          requests: # guaranteed resources for this container
            cpu: 200m
---
apiVersion: v1
kind: Service
metadata:
  name: epilepsy-prediction-service
  labels:
    app: eeg-app
    component: epilepsy-prediction
spec:
  selector:
    app: eeg-app
    component: epilepsy-prediction
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
  type: LoadBalancer
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: epilepsy-prediction-hpa
spec:
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - resource:
      name: cpu
      target:
        averageUtilization: 50    # target: 50% use of CPU by POD
        type: Utilization
    type: Resource
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: epilepsy-prediction-deployment